{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastAPI Text Classification and Sentiment Analysis\n",
    "\n",
    "This project sets up a FastAPI application that performs text classification using the Hugging Face `transformers` library. The application uses a sentiment analysis model, but this can be customized for other NLP tasks. It allows requests from any origin using CORS middleware and runs in a Jupyter Notebook environment with `nest_asyncio` to avoid event loop issues.\n",
    "\n",
    "### Required Libraries\n",
    "\n",
    "To run the code, you need to install the following libraries:\n",
    "\n",
    "```bash\n",
    "!pip install fastapi uvicorn transformers torch nest_asyncio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [932]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "ERROR:    [Errno 10048] error while attempting to bind on address ('0.0.0.0', 8000): [winerror 10048] only one usage of each socket address (protocol/network address/port) is normally permitted\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n"
     ]
    }
   ],
   "source": [
    "# Required libraries\n",
    "#!pip install fastapi uvicorn transformers torch nest_asyncio\n",
    "\n",
    "from fastapi import FastAPI\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from transformers import pipeline\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "from threading import Thread\n",
    "\n",
    "# Apply nest_asyncio to fix event loop issues in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load the model for text classification\n",
    "classifier = pipeline('sentiment-analysis')  # You can change the task if needed\n",
    "\n",
    "# Create FastAPI app\n",
    "app = FastAPI()\n",
    "\n",
    "# Add CORS middleware to allow access from the browser\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],  # Allow all origins\n",
    "    allow_methods=[\"*\"],  # Allow all methods\n",
    "    allow_headers=[\"*\"]   # Allow all headers\n",
    ")\n",
    "\n",
    "# Define a route for text classification\n",
    "@app.get(\"/classify/{text}\")\n",
    "async def classify(text: str):\n",
    "    result = classifier(text)\n",
    "    return {\"label\": result[0]['label'], \"score\": result[0]['score']}\n",
    "\n",
    "# Function to run FastAPI in background\n",
    "def run_server():\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
    "\n",
    "# Start FastAPI in a separate thread\n",
    "server_thread = Thread(target=run_server, daemon=True)\n",
    "server_thread.start()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification API with FastAPI and Hugging Face's DistilBERT\n",
    "\n",
    "This project implements a **text classification** API using **FastAPI** and Hugging Face's pre-trained **DistilBERT** model. The API allows you to classify input text into categories such as \"POSITIVE\", \"NEGATIVE\", or \"NEUTRAL\" based on the model's predictions. It is suitable for use cases like sentiment analysis or simple text classification.\n",
    "\n",
    "## Features\n",
    "\n",
    "- Pre-trained **DistilBERT** model for text classification.\n",
    "- RESTful API built with **FastAPI**.\n",
    "- **CORS** middleware enabled for browser-based access.\n",
    "- Confidence-based responses for more granular feedback.\n",
    "\n",
    "## Installation\n",
    "\n",
    "To get started with the project, clone the repository and install the required dependencies.\n",
    "\n",
    "### Clone the repository\n",
    "```bash\n",
    "git clone https://github.com/your-username/your-repo-name.git\n",
    "cd your-repo-name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\Admin\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\transformers\\tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [932]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:53084 - \"GET /classify/Hello HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "# Install the required libraries (uncomment if necessary)\n",
    "# !pip install fastapi uvicorn transformers torch nest_asyncio\n",
    "\n",
    "from fastapi import FastAPI\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from transformers import pipeline\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "from threading import Thread\n",
    "\n",
    "# Apply nest_asyncio to fix event loop issues in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load the pre-trained model for text classification (using DistilBERT)\n",
    "classifier = pipeline('text-classification', model='distilbert-base-uncased')\n",
    "# classifier = pipeline('text-classification', model='news-category-finetuned-model')\n",
    "\n",
    "\n",
    "# Create a FastAPI app\n",
    "app = FastAPI()\n",
    "\n",
    "# Add CORS middleware to allow access from any browser\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],  # Allow all origins\n",
    "    allow_methods=[\"*\"],  # Allow all methods\n",
    "    allow_headers=[\"*\"]   # Allow all headers\n",
    ")\n",
    "\n",
    "# Define a route for text classification\n",
    "@app.get(\"/classify/{text}\")\n",
    "async def classify(text: str):\n",
    "    result = classifier(text)\n",
    "    category = result[0]['label']\n",
    "    confidence = result[0]['score']\n",
    "\n",
    "    # Predefined example responses based on confidence and category\n",
    "    if category == \"POSITIVE\" and confidence > 0.95:\n",
    "        message = \"The model is highly confident that the input text belongs to the category 'POSITIVE', with a confidence score of {:.2f}.\".format(confidence)\n",
    "    elif category == \"NEGATIVE\" and confidence > 0.95:\n",
    "        message = \"The model strongly believes that the input text belongs to the category 'NEGATIVE', with a high confidence score of {:.2f}.\".format(confidence)\n",
    "    elif category == \"NEUTRAL\":\n",
    "        message = \"The model predicts that the input text belongs to the category 'NEUTRAL' with a confidence score of {:.2f}.\".format(confidence)\n",
    "    elif category == \"POSITIVE\" and confidence < 0.60:\n",
    "        message = \"The model predicts that the input text might be 'POSITIVE', but the confidence score is low at {:.2f}.\".format(confidence)\n",
    "    elif category == \"NEGATIVE\" and confidence < 0.60:\n",
    "        message = \"The model predicts that the input text may belong to the category 'NEGATIVE', but the confidence is moderate at {:.2f}.\".format(confidence)\n",
    "    else:\n",
    "        message = \"The model predicts that the input text belongs to the category '{}' with a confidence score of {:.2f}.\".format(category, confidence)\n",
    "    \n",
    "    # Returning response\n",
    "    return {\n",
    "        \"category\": category,\n",
    "        \"confidence\": confidence,\n",
    "        \"message\": message\n",
    "    }\n",
    "\n",
    "# Function to run FastAPI in the background\n",
    "def run_server():\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
    "\n",
    "# Start FastAPI in a separate thread\n",
    "server_thread = Thread(target=run_server, daemon=True)\n",
    "server_thread.start()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
