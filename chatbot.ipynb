{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastAPI Text Classification and Sentiment Analysis\n",
    "\n",
    "This project sets up a FastAPI application that performs text classification using the Hugging Face `transformers` library. The application uses a sentiment analysis model, but this can be customized for other NLP tasks. It allows requests from any origin using CORS middleware and runs in a Jupyter Notebook environment with `nest_asyncio` to avoid event loop issues.\n",
    "\n",
    "### Required Libraries\n",
    "\n",
    "To run the code, you need to install the following libraries:\n",
    "\n",
    "```bash\n",
    "!pip install fastapi uvicorn transformers torch nest_asyncio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [11800]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:50700 - \"GET /classify/Paghal HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:50703 - \"GET /classify/chor HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:50705 - \"GET /classify/sex HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:50777 - \"GET /classify/spam HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "# Required libraries\n",
    "#!pip install fastapi uvicorn transformers torch nest_asyncio\n",
    "\n",
    "from fastapi import FastAPI\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from transformers import pipeline\n",
    "import nest_asyncio\n",
    "import uvicorn\n",
    "from threading import Thread\n",
    "\n",
    "# Apply nest_asyncio to fix event loop issues in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Load the model for text classification\n",
    "classifier = pipeline('sentiment-analysis')  # You can change the task if needed\n",
    "\n",
    "# Create FastAPI app\n",
    "app = FastAPI()\n",
    "\n",
    "# Add CORS middleware to allow access from the browser\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],  # Allow all origins\n",
    "    allow_methods=[\"*\"],  # Allow all methods\n",
    "    allow_headers=[\"*\"]   # Allow all headers\n",
    ")\n",
    "\n",
    "# Define a route for text classification\n",
    "@app.get(\"/classify/{text}\")\n",
    "async def classify(text: str):\n",
    "    result = classifier(text)\n",
    "    return {\"label\": result[0]['label'], \"score\": result[0]['score']}\n",
    "\n",
    "# Function to run FastAPI in background\n",
    "def run_server():\n",
    "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
    "\n",
    "# Start FastAPI in a separate thread\n",
    "server_thread = Thread(target=run_server, daemon=True)\n",
    "server_thread.start()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
